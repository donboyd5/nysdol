---
format: html
editor-options: 
  chunk-output-type: console
editor:
  markdown:
    canonical: true  
---

# Get and save data

Get qcew.zip from the NYSDOL website: https://dol.ny.gov/quarterly-census-employment-and-wages Direct link to [qcew.zip](https://statistics.labor.ny.gov/qcew.zip).

If downloading directly, the file may be too large for the default, typically 60 seconds, in which case increase the timeout:

> timeout \<- getOption("timeout") \
> options(timeout = max(300, timeout))\
> download.file(...., mode="wb") \
> options(timeout = timeout)

CAUTION: Sometimes NYSDOL uses unsupported ZIP compression method (9: deflation-64-bit) If so, either convert to regular zip using winrar (or some other method) or extract and read.

## Setup

```{r}
#| label: libraries

libs <- function() {
  library(rlang)
  library(tidyverse)
  tprint <- 75 # default tibble print
  options(tibble.print_max = tprint, tibble.print_min = tprint) # show up to tprint rows
  library(purrr)
  library(archive) # better than using unz

  library(fs)

  # tools
  library(vroom)
  library(readxl)
  library(openxlsx) # for writing xlsx files
  library(lubridate)
  library(RColorBrewer)
  library(RcppRoll)
  library(fredr)
  library(tidycensus)

  # boyd libraries
  library(btools)
  library(bdata)
  library(bggtools)
  library(bmaps)

  # graphics
  library(scales)
  library(ggbeeswarm)
  library(patchwork)
  library(gridExtra)
  library(ggrepel)
  library(ggbreak)

  # tables
  library(formattable)
  library(knitr)
  library(kableExtra)
  library(DT)
  library(gt)
  library(gtExtras)
  library(janitor)
  library(skimr)
  library(vtable)

  # maps
  # library(maps)
  # # https://cran.r-project.org/web/packages/usmap/vignettes/mapping.html
  # library(usmap)
}

suppressPackageStartupMessages(libs())

rm(libs)

```

```{r}
#| label: constants

DRAW <- r"(E:\data\qcew\nysdol)"
DDATA <- fs::path(DRAW, "data")

# County names as found in the NYSDOL QCEW

constants <- list()
constants$mtaregion <- read_csv(
  "area
Bronx County
Kings County
New York County
Queens County
Richmond County

Dutchess County
Nassau County
Orange County
Putnam County
Rockland County
Suffolk County
Westchester County
",
  show_col_types = FALSE
)

constants$nyc <- constants$mtaregion |>
  slice_head(n = 5)

constants


```

## Download qcew.zip if needed

```{r}
#| label: download-qcew.zip
#| eval: false

qurl <- "https://statistics.labor.ny.gov/qcew.zip"
fname <- fs::path_file(qurl)

timeout <- getOption("timeout")
options(timeout = max(300, timeout))
download.file(qurl, destfile = fs::path(DRAW, fname), mode = "wb")
options(timeout = timeout)

```

## Recompress qcew.zip if needed

Takes ~ 15 secs

```{r}
#| label: recompress
#| eval: false

a <- proc.time()
zip_file <- "qcew.zip"
output_file <- "qcew_recompressed.zip"
zpath <- paste0(DRAW, "\\", zip_file)
opath <- paste0(DRAW, "\\", output_file)

extract_dir <- "temp_extract"
seven_zip_path <- "C:/Program Files/7-Zip/7z.exe"

unlink(opath, recursive = TRUE) # Clean up
unlink(extract_dir, recursive = TRUE) # Clean up

if (!dir.exists(extract_dir)) dir.create(extract_dir) # Create extraction directory
system2(
  seven_zip_path,
  args = c("x", shQuote(zpath), paste0("-o", extract_dir))
) # Extract

original_wd <- getwd() # Get current working directory to return to later
setwd(extract_dir) # Change to extraction directory and compress contents
system2(
  seven_zip_path,
  args = c(
    "a",
    "-tzip",
    "-mx=5",
    # shQuote(file.path(original_wd, output_file)),
    shQuote(opath),
    "*"
  )
) # Recompress
setwd(original_wd) # Return to original directory
unlink(extract_dir, recursive = TRUE) # Clean up
b <- proc.time()
b - a

```

## Get county information and save raw file

Takes about 10 seconds not counting save.

```{r}
#| label: get-qcew

# get names of the csv quarterly files and then read them

# un-comment one of the following
# fname <- "qcew.zip"
fname <- "qcew_recompressed.zip" # if recompressed externally
zpath <- fs::path(DRAW, fname)
zfiles <- zip::zip_list(zpath)

csvfiles <- zfiles |>
  filter(str_starts(filename, "qcew_quarter_")) |>
  pull(filename)

# Pipe directly into vroom
system.time(
  df <- vroom(purrr::map(csvfiles, \(x) archive::archive_read(zpath, file = x)))
) # use archive_read rather than unz because it handles more kinds of compressed files; 10 secs

count(df, YEAR, QUARTER) |> filter(YEAR == max(YEAR)) # make sure it has the latest quarter
system.time(saveRDS(df, fs::path(DDATA, "qcew_raw.rds")))

```

## START to clean, subset, and save qcew data

```{r}
#| label: clean-and-subset

system.time(df <- readRDS(fs::path(DDATA, "qcew_raw.rds"))) # 17 secs
glimpse(df)

# do minimally required cleaning
a <- proc.time()
owner_order <- c(
  "Total Private and Government",
  "Private",
  "Total Government",
  "Federal Government",
  "State Government",
  "Local Government"
)

df2 <- df |>
  rename_with(str_to_lower) |>
  # slice_head(n = 10) |>
  mutate(
    date = lubridate::yq(paste(year, quarter)),
    areatype = str_to_lower(areatype),
    mta = area %in% constants$mtaregion,
    nyc = area %in% constants$nyc,
    naics_level = as.integer(naics_level),
    owner = factor(owner, levels = owner_order)
  ) |>
  select(
    date,
    areatype,
    area,
    mta,
    nyc,
    naics_level,
    naics,
    naics_title,
    owner,
    estab,
    mnth1emp,
    mnth2emp,
    mnth3emp,
    totwage
  )
b <- proc.time()
b - a # 35 secs

system.time(saveRDS(df2, fs::path(DDATA, "qcew_clean.rds"))) # 48 secs

count(df2, owner)


# 1 Federal Government            118244
# 2 Local Government              266394
# 3 Private                      7699135
# 4 State Government              149627
# 5 Total Government              619276
# 6 Total Private and Government 8739375

glimpse(df2)
count(df2, date) |> ht()
# count(df2, areatype)
# count(df2, areatype, owner)

df3 <- df2 |>
  filter(areatype %in% c("State", "County")) |>
  mutate(areatype = str_to_lower(areatype)) |>
  mutate(
    mta = area %in% constants$mtaregion,
    nyc = area %in% constants$nyc
  ) # reasonably fast
glimpse(df3)


df4 <- df3 |>
  filter(
    (areatype == "state") |
      mta,
    owner %in% c("Total Private and Government", "Private")
  ) |>
  select(
    areatype,
    area,
    year,
    quarter,
    naics,
    naics_level,
    naics_title,
    owner,
    totwage
  )

saveRDS(df4, here::here("data", "qmta.rds"))

```

## Explore

```{r}
#| label: explore

system.time(qcew <- readRDS(fs::path(DDATA, "qcew_clean.rds")))


qmta <- readRDS(fs::path(DDATA, "qmta.rds"))
glimpse(qmta)

```

```{r stop_here, echo=FALSE}
knitr::knit_exit()
```

## Example of temp folder approach

```{r}
#| label: faster-reading-with-temp-folder
#| eval: false

a <- proc.time()
temp_dir <- tempfile("extracted_files_") # Creates a unique temp folder name
dir.create(temp_dir) # Actually creates the folder

# 3. Extract ONLY the needed files into the temp folder
unzip(
  zipfile = zpath,
  files = csvfiles,
  exdir = temp_dir,
  junkpaths = TRUE # Removes internal ZIP folder structure (simplifies paths)
)

# 4. Read all files at once with vroom (row-binds them if same structure)
df_combined <- vroom(
  file = file.path(temp_dir, csvfiles), # Full paths to extracted files
  id = "source_file" # Adds column tracking which file each row came from
)

# 5. Clean up: Delete the temp folder and all contents
unlink(temp_dir, recursive = TRUE)
b <- proc.time()
b - a # 6.7 secs

```
